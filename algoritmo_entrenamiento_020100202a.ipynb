{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Implementación del perceptrón en Python según el algoritmo y ejemplo dados."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, learning_rate=0.01, n_iters=1000):\n",
        "        # Inicializa el perceptrón con la tasa de aprendizaje y el número de iteraciones\n",
        "        self.learning_rate = learning_rate\n",
        "        self.n_iters = n_iters\n",
        "        self.weights = None\n",
        "        self.threshold = None\n",
        "\n",
        "    def activation_function(self, x):\n",
        "        # Función de activación escalón que retorna 1 si x >= 0, sino retorna 0\n",
        "        return np.where(x >= 0, 1, 0)\n",
        "\n",
        "    def fit(self, X, D):\n",
        "        # Entrena el modelo usando los datos de entrada X y las salidas deseadas D\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        # Inicializar pesos y umbral con valores aleatorios reales entre -1 y +1\n",
        "        self.weights = np.random.uniform(-1.0, 1.0, n_features)\n",
        "        self.threshold = np.random.uniform(-1.0, 1.0)\n",
        "\n",
        "        # Iterar por el número de épocas especificado\n",
        "        for epoch in range(self.n_iters):\n",
        "            print(f\"\\nÉpoca {epoch + 1}/{self.n_iters}\")\n",
        "            \n",
        "            # Iterar por cada muestra en el conjunto de datos\n",
        "            for idx, x_i in enumerate(X):\n",
        "                # Paso 3: Calcula la salida (y) usando la función de activación\n",
        "                y = self.activation_function(np.dot(x_i, self.weights) - self.threshold)\n",
        "\n",
        "                # Paso 4: Calcular el error como la diferencia entre el valor deseado y la salida\n",
        "                error = D[idx] - y\n",
        "\n",
        "                # Imprimir el valor deseado, salida y error para la muestra actual\n",
        "                print(f\"  Muestra {idx + 1}: Valor deseado = {D[idx]}, Salida (y) = {y}, Error = {error}\")\n",
        "\n",
        "                # Paso 5: Ajuste de pesos en función del error\n",
        "                self.weights += self.learning_rate * error * x_i\n",
        "                # Ajuste del umbral usando la tasa de aprendizaje y el error\n",
        "                self.threshold -= self.learning_rate * error\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Realiza la predicción para un conjunto de datos de entrada X\n",
        "        linear_output = np.dot(X, self.weights) - self.threshold\n",
        "        return self.activation_function(linear_output)\n",
        "\n",
        "# Ejemplo de uso\n",
        "if __name__ == \"__main__\":\n",
        "    # Datos de entrada X y etiquetas D para una compuerta lógica OR\n",
        "    X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "    D = np.array([0, 1, 1, 1])  # Salidas esperadas de la compuerta OR\n",
        "\n",
        "    # Crear una instancia del perceptrón con una tasa de aprendizaje de 0.1 y 10 iteraciones\n",
        "    perceptron = Perceptron(learning_rate=0.1, n_iters=10)\n",
        "    # Entrenar el perceptrón con los datos de entrada X y las etiquetas D\n",
        "    perceptron.fit(X, D)\n",
        "\n",
        "    # Predicción de las salidas para los datos de entrada X\n",
        "    predictions = perceptron.predict(X)\n",
        "    print(\"Predicciones finales:\", predictions)\n"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}
